{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2baf6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import broadcast\n",
    "from pyspark import StorageLevel \n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302efb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark with optimized configurations\n",
    "spark = SparkSession.builder.appName(\"NAD_Geocoding\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ecdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the processed transaction data\n",
    "processed_path = '/mmfs1/projects/f8d7c0/2024-25/Gate City Bank/Agustin/Gate_City_processed_completed_TEST.csv'\n",
    "\n",
    "df = spark.read.csv(processed_path, header=True, inferSchema=True)\n",
    "\n",
    "# 2. Load the cleaned NAD data\n",
    "nad_path = '/mmfs1/projects/f8d7c0/2024-25/Gate City Bank/Agustin/NAD_r18_clean.csv'\n",
    "nad_df = spark.read.csv(nad_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82a3234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAD DataFrame size: 77767367 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[NAD_No: string, NAD_st: string, NAD_county: string, NAD_City: string, NAD_state: string, Zip_Code: string, NAD_longitude: string, NAD_latitude: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Data preparation and cleaning\n",
    "print(f\"NAD DataFrame size: {nad_df.count()} rows\")\n",
    "\n",
    "nad_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898ef10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Extract street number and name from `term_street` (using NAD column names)\n",
    "df_prepared = df.withColumn(\n",
    "    \"term_street_number\", regexp_extract(col(\"term_street\"), r\"^(\\d+)\", 1)\n",
    ").withColumn(\n",
    "    \"term_street_name\",\n",
    "    regexp_replace(\n",
    "        # First remove the house number and spaces\n",
    "        regexp_replace(col(\"term_street\"), r\"^\\d+\\s*\", \"\"),\n",
    "        # Then remove ALL street types, directions, and special characters\n",
    "        r\"(?i)[.#]|\\b(st|street|rd|road|ave|avenue|blvd|boulevard|dr|drive|ln|lane|way|ct|court|cir|circle|ter|terrace|pl|place|pkwy|parkway|aly|alley|expy|expressway|hwy|highway|sq|square|tpke|turnpike|n|s|e|w|north|south|east|west)(\\.?)\\b\",\n",
    "        \"\"\n",
    "    )\n",
    ").withColumn(\n",
    "    \"term_street_name\", \n",
    "    trim(regexp_replace(col(\"term_street_name\"), r\"^\\W+|\\W+$\", \"\"))  # Remove leading/trailing non-word chars\n",
    ")\n",
    "\n",
    "# Prepare NAD data using correct column names\n",
    "nad_prepared = nad_df.withColumn(\n",
    "    \"NAD_streetNumber\", trim(col(\"NAD_No\"))  # Using NAD_No for street number\n",
    ").withColumn(\n",
    "    \"NAD_streetName\", trim(col(\"NAD_st\"))    # Using NAD_st for street name\n",
    ")\n",
    "\n",
    "# Create join keys (state|city|street_number|street_name)\n",
    "df_prepared = df_prepared.withColumn(\n",
    "    \"join_key\",\n",
    "    concat_ws(\"|\",\n",
    "        lower(trim(col(\"TERM_State\"))),\n",
    "        lower(trim(col(\"TERM_City\"))),\n",
    "        trim(col(\"term_street_number\")),\n",
    "        lower(trim(col(\"term_street_name\")))\n",
    "    )\n",
    ")\n",
    "\n",
    "nad_prepared = nad_prepared.withColumn(\n",
    "    \"join_key\",\n",
    "    concat_ws(\"|\",\n",
    "        lower(trim(col(\"NAD_state\"))),\n",
    "        lower(trim(col(\"NAD_City\"))),\n",
    "        trim(col(\"NAD_streetNumber\")),\n",
    "        lower(trim(col(\"NAD_streetName\")))\n",
    "    )\n",
    ").select(\"join_key\", \"NAD_longitude\", \"NAD_latitude\")\n",
    "\n",
    "# Perform the join\n",
    "result_df = df_prepared.join(\n",
    "    nad_prepared,\n",
    "    on=\"join_key\",\n",
    "    how=\"left\"\n",
    ").drop(\"join_key\", \"term_street_number\", \"term_street_name\")\n",
    "\n",
    "# Handle records with term_street_flag < 1 (no street data)\n",
    "non_street_records = df.filter(col(\"term_street_flag\") < 1)\n",
    "final_result = result_df.unionByName(\n",
    "    non_street_records.withColumn(\"NAD_longitude\", lit(None))\n",
    "                     .withColumn(\"NAD_latitude\", lit(None))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4c964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save results (updated with pre-processing for Tableau compatibility)\n",
    "result_df = df_prepared.join(\n",
    "    nad_prepared,\n",
    "    on=\"join_key\",\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    df_prepared[\"*\"],  # Keep all original columns\n",
    "    nad_prepared[\"NAD_longitude\"],\n",
    "    nad_prepared[\"NAD_latitude\"]\n",
    ")\n",
    "\n",
    "# Drop the unnecessary columns before saving\n",
    "result_df = result_df.drop(\"2022_NAICS_Title\",\"term_street_number\", \"term_street_name\", \"join_key\")\n",
    "\n",
    "# Ensure consistent column order, clean headers, and proper CSV formatting\n",
    "output_path = '/mmfs1/projects/f8d7c0/2024-25/Gate City Bank/Agustin/Gate_City_with_NAD_FINAL.csv'\n",
    "\n",
    "# Write with explicit CSV settings to avoid Tableau union issues\n",
    "(\n",
    "    result_df\n",
    "    .coalesce(20)  # Reduce partitions to minimize file splits (optional)\n",
    "    .write\n",
    "    .csv(\n",
    "        output_path,\n",
    "        header=True,\n",
    "        mode=\"overwrite\",\n",
    "        quote='\"',       # Force consistent quoting\n",
    "        escape='\"',      # Handle escaped quotes uniformly\n",
    "        encoding=\"UTF-8\", # Standard encoding\n",
    "        lineSep=\"\\n\",    # Explicit line separator\n",
    "        emptyValue=\"\"    # Replace nulls with empty strings\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2703ac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset columns:\n",
      "['SICSUBCD', 'TXN_DESCRIPTION', 'TERM_ADDR', 'HASHED_MERCH_ID', 'Related_SIC_Code_Description', 'Online_status', 'State', 'Country', 'Parent_Company', 'Parent_Company_Flag', 'City', 'Address_Flag', 'Address', 'TERM_State', 'TERM_City', 'term_street', 'term_street_flag', 'Company', 'COMPANY_KEY', 'NAD_longitude', 'NAD_latitude']\n",
      "\n",
      "Geocoding completed successfully!\n",
      "Total records processed: 10208188\n",
      "Records with coordinates matched: 704826\n",
      "Output saved to: /mmfs1/projects/f8d7c0/2024-25/Gate City Bank/Agustin/Gate_City_with_NAD_FINAL.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal dataset columns:\")\n",
    "print(result_df.columns)\n",
    "print(\"\\nGeocoding completed successfully!\")\n",
    "print(f\"Total records processed: {df.count()}\")\n",
    "print(f\"Records with coordinates matched: {result_df.filter(col('NAD_longitude').isNotNull()).count()}\")\n",
    "print(f\"Output saved to: {output_path}\")\n",
    "\n",
    "# Sample output\n",
    "#print(\"\\nSample geocoded records:\")\n",
    "#result_df.select(\"TERM_City\", \"TERM_State\", \"term_street\", \"NAD_longitude\", \"NAD_latitude\") \\\n",
    "#         .filter(col(\"NAD_longitude\").isNotNull()) \\\n",
    "#         .show(5, truncate=False)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae88af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
